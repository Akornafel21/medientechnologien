<html>
<head>
<title></title>
<link rel="stylesheet" type="text/css" href="format.css">
<style type="text/css">

                 a:link {font-family:Arial;        font-size:10pt;        text-decoration:none;}
                a:visited {font-family:Arial; font-size:10pt; text-decoration:none;}
                a:hover {color:#FF3333; text-decoration:none; font-weight:normal; font-size:10pt;}
</style>
</head>

<body>

<iframe src="oben.html" width="800" height="120" name="IFrame3" id="IFrame3" scrolling="no" frameborder="0">
         <p>Ihr Browser kann leider keine eingebe5tteten Frames anzeigen:Sie k&ouml;nnen die eingebettete Seite &uuml;ber den
         folgenden.</p>
</iframe>

<h1>Uebung 1</h1>

<h2>Aufgabe 1 – Audiodateien erzeugen und einlesen</h2>
<h3>Aufgabe 1 a.</h3>
<p>Schneide aus den dir zugeschickten Audio-Files ab dem Zeitpunkt jeweils ein Stück mit der Länge 5
Sekunden und speichere dieses als WAV-Datei ab. Parameter für Musik: fa=44,1 kHz, stereo, für
Sprache: fa=8 kHz mono, beide 16 bit Auflösung. Beim Schneiden achtest du darauf, dass der
Schnitt am Beginn einer musikalischen Figur bzw. eines Satzes liegt.</p>
<p>Musikaufnahme</p>
<audio controls><source src="audio/musik_Bytewave.wav" type="audio/wav"></audio>
<audio controls><source src="audio/Sprache_Bytewave.wav" type="audio/wav"></audio>
<br><h3>Aufgabe 1 b.</h3>
<p>Erkläre, warum die Audio-Files unterschiedliche Abtastfrequenzen haben</p>
        <!--Füge bei p die Lösung ein die wir schon erarbeitet hatten -->
<p>Loesung</p>

<br><h3>Aufgabe 1 c.</h3>
<p>Lies die Musik- und die Sprachdatei mit wave_io ein und erkläre die Angaben im Header</p>
<p><img src="bilder/musik_header.jpeg" height="150" alt="Bild kann nicht geladen werden.">
        <img src="bilder/sprache_header.jpeg" height="150" alt="Bild kann nicht geladen werden.">
         <!--bei dem bild2 (sprache) stimmt was nicht, die sprache sollte nur 1 channel haben kannst du das
                 nochmal überprüfen? -->
                 <!--musst noch die sine datei in ordner machen -->
</p>
<p><b>Channels:</b> sind die Kanäle, bei Sprache ist es 1 Kanal(mono)
</br> und bei Musik sind es 2 Kanäle(stereo)
</br><b>Frames:</b> enthalten die Samples für alle Kanäle
</br><b>Sample Rate:</b> Abtastrate / Abtastfrequenz, sagt wie oft pro Sekunde das Audiosignal gemessen wird.
</br><b>Valid Bits:</b> ist die Auflösung 
</br><b>Bytes per Sample:</b> Anzahl der Bytes pro Sample zeigt, wie viel Speicherplatz eine einzelne Messung braucht
</p> 
                
       

        
<br><h3>Aufgabe 1 d.</h3>
<p>Berechne die Bitrate für die beiden Dateien</p>
<p>Allgemein: Bitrate = Abtastfrequenz * Bits * Kanäle
</br>Berechnung für die Musik-Datei
</br> Bitrate = 44100 * 16 * 2 = 1.411.200 bits/s 
</br>Berechnung für die Sprach-Datei
</br> Bitrate = 16000 * 16 * 1 = 256.000 bits/s  <!--verstehe die lösung von den andern nicht, dachte so weil nur 1 Kanal -->
</p>
<br>
<h2>Aufgabe 2 – Aliasing</h2>
<h3>Aufgabe 2 a und b</h3>
<br><p>Rauschen</p>
<p>Modifiziere wave_io dahingehend, dass die Samples in der WAV-Datei in eine (lesbare) ASCII-
        Datei geschrieben werden. Lies die von mir geschickten Sinusdateien (Sampling-Frequenz: 16 kHz)
        ein und bestimme aus den resultierenden Zahlenfolgen in der ASCII-Datei die Frequenz der Sinus-
        Schwingungen. Begründe!</p>
        <!--einfügen sine dateien-->
<audio controls><source src="rauschen.wav" type="audio/wav"></audio>
<audio controls><source src="rauschen.wav" type="audio/wav"></audio>
<p><!--Loesung--></p>

<br><h3>Aufgabe 2 c.</h3>
<p>Bei der zeitlichen Diskretisierung eines Analogsignals muss das sogenannte Abtasttheorem
        eingehalten werden. Wie lautet es und wie lässt sich der Grenzfall, für den es gerade noch gilt,
        illustrieren? Erstelle hierzu eine Zeichnung und erläutere.</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 2 d.</h3>
<p>Bei herkömmlichen Soundkarten tritt systembedingt kein Aliasing auf, weil das Audiosignal stets
        geeignet vorbehandelt wird. Wie sieht diese Vorbehandlung aus?</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 2 e.</h3>
<p>Mit einem kleinen Trick lässt sich Aliasing jedoch nachweisen. Diese auch als Down-Sampling
        bekannte Methode besteht darin, dass man bei einer WAV-Datei z.B. jeden zweiten Abtastwert
        wegwirft. Man erhält so eine Wellenform, die genau die Hälfte der ursprünglichen Abtastfrequenz
        aufweist. Wenn man das Signal nicht vorher bandbegrenzt hat, können Aliasing-Verzerrungen
        hörbar werden. Modifiziere wave_io dahingehend, dass vom eingelesenen Audiosignal jeder zweite Abtastwert
        verworfen wird und das resultierende Signal abgespeichert wird. Der Header muss natürlich
        entsprechend verändert werden</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 2 f.</h3>
<p>Wende das erstellte Programm auf die von mir geschickten Sinusdateien an (sine_hiXX.wav und
        sine_loXX.wav) an. Welche Frequenzen erscheinen nach dem Down-Sampling? Was würde
        passieren, wenn man geeignet bandbegrenzen würde?</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 2 g.</h3>
<p>Nun wende das Downsampling auf deine Sprachdatei an und beschreibe, wie sich der Klang
        verändert. Erkläre, warum das passiert!</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 a.</h3>
<p>Die herkömmlichen PC-Soundkarten arbeiten meist entweder mit 16 oder 8 bit-Auflösung. Wie
        groß ist die Anzahl bei diesen beiden Werten darstellbaren Amplitudenwerten?</p>
<p>Allgemein: Anzahl der Werte = 2^bits
</br> 16 bit-Auflösung = 2^16 = 65.536
</br> 8 bit-Auflösung = 2^8 = 256
</p>

<br><h3>Aufgabe 3 b.</h3>
<p>Modifiziere wave_io dahingehend, dass die Bitanzahl reduziert wird. Dazu werden alle Samples
        durch eine Potenz von 2 geteilt (Integer-Division ohne Rest). Damit das resultierende Signal nicht
        leiser wird als das Original, wird die Operation durch Multiplikation mit derselben 2er Potenz
        kompensiert. Zu beachten: Der Datentyp hat nach wie vor 16 bit!</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 c.</h3>
<p>Mit dem entstandenen Programm sollen nun die in Aufgabe 1 erzeugten Wave-Dateien (Sprache
        und Musik) bitreduziert werden. Ab welcher Bitanzahl tritt eine hörbare, also deutliche
        Verschlechterung der Qualität ein? Bei wie viel Bit ist das Sprachsignal noch verständlich?</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 d.</h3>
<p>Was charakterisiert das entstehende Quantisierungsgeräusch bei der Bitreduzierung und macht es
        besonders störend?</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 e.</h3>
<p>Modifiziere dein Programm noch einmal so, dass auch das Differenzsignal zwischen Original und
        bitreduziertem Signal, d.h. der Quantisierungsfehler ausgegeben werden kann. Dabei musst du
        bedenken, dass z.B. bei der 1 Bit Reduzierung das Quantisierungsrauschen nur von -1 bis +1
        verlaufen würde. Dieser Wertebereich wäre viel zu klein, als dass man das Rauschen beim
        Abspielen als 16bit-Wert noch hören könnte. Daher muss das Rauschen durch Multiplikation mit
        einer 2er Potenz verstärkt werden. In anderen Worten: Hat man vorher durch 2^n geteilt, sollte
        man das Differenzsignal vor dem Abspeichern mit 2^(16-n-1) multiplizieren. So ist sichergestellt,
        dass der Verstärkungsfaktor mit der Anzahl der gelöschten Bits kleiner wird</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 f.</h3>
<p>Welchen Charakter hat das Rauschen bei einer Reduktion um 1bit und wie verändert es sich bei
        zunehmender Bit-Reduktion?</p>
<p><!--Loesung--></p>

</body>
</html>
