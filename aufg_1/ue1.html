<html>
<head>
<title></title>
<link rel="stylesheet" type="text/css" href="format.css">
<style type="text/css">

                 a:link {font-family:Arial;        font-size:10pt;        text-decoration:none;}
                a:visited {font-family:Arial; font-size:10pt; text-decoration:none;}
                a:hover {color:#FF3333; text-decoration:none; font-weight:normal; font-size:10pt;}
</style>
</head>

<body>

<iframe src="oben.html" width="800" height="120" name="IFrame3" id="IFrame3" scrolling="no" frameborder="0">
         <p>Ihr Browser kann leider keine eingebe5tteten Frames anzeigen:Sie k&ouml;nnen die eingebettete Seite &uuml;ber den
         folgenden.</p>
</iframe>

<h1>Uebung 1</h1>

<h2>Aufgabe 1 – Audiodateien erzeugen und einlesen</h2>
<h3>Aufgabe 1 a.</h3>
<p>Schneide aus den dir zugeschickten Audio-Files ab dem Zeitpunkt jeweils ein Stück mit der Länge 5 Sekunden und speichere        
</br>dieses als WAV-Datei ab. Parameter für Musik: fa=44,1 kHz, stereo, für Sprache: fa=8 kHz mono, beide 16 bit Auflösung. 
</br>Beim Schneiden achtest du darauf, dass der Schnitt am Beginn einer musikalischen Figur bzw. eines Satzes liegt.</p>
<p>Musikaufnahme</p>
<audio controls><source src="audio/musik_Bytewave.wav" type="audio/wav"></audio>
<audio controls><source src="audio/Sprache_Bytewave.wav" type="audio/wav"></audio>
<br><h3>Aufgabe 1 b.</h3>
<p>Erkläre, warum die Audio-Files unterschiedliche Abtastfrequenzen haben</p>
<p>Die Abtastfrequenz für die Musik-Datei ist 44,1 kHZ, währenddessen die Sprach-Datei 8kHZ beträgt. 
</br>Das hat den Grund, das die wesentlichen Aspekte von Stimmen eine deutlich niedrigere Requenz benötigt, um erfasst zu werden
</p>

<br><h3>Aufgabe 1 c.</h3>
<p>Lies die Musik- und die Sprachdatei mit wave_io ein und erkläre die Angaben im Header</p>
<p><img src="bilder/musik_header.jpeg" height="150" alt="Bild kann nicht geladen werden.">
        <img src="bilder/sprache_header.jpeg" height="150" alt="Bild kann nicht geladen werden.">
      
                
</p>
<p><b>Channels:</b> sind die Kanäle
</br><b>Frames:</b> enthalten die Samples für alle Kanäle
</br><b>Sample Rate:</b> Abtastrate / Abtastfrequenz, sagt wie oft pro Sekunde das Audiosignal gemessen wird.
</br><b>Valid Bits:</b> ist die Auflösung 
</br><b>Bytes per Sample:</b> Anzahl der Bytes pro Sample zeigt, wie viel Speicherplatz eine einzelne Messung braucht
</p> 
                
       

        
<br><h3>Aufgabe 1 d.</h3>
<p>Berechne die Bitrate für die beiden Dateien</p>
<p>Allgemein: Bitrate = Abtastfrequenz * Bits * Kanäle
</br>Berechnung für die Musik-Datei
</br> Bitrate = 44100 * 16 * 2 = 1.411.200 bits/s 
</br>Berechnung für die Sprach-Datei
</br> Bitrate = 16000 * 16 * 2 = 511.200 bits/s  
</p>
<br>
<h2>Aufgabe 2 – Aliasing</h2>
<h3>Aufgabe 2 a. </h3>
<br><p>Rauschen</p>
<p>Modifiziere wave_io dahingehend, dass die Samples in der WAV-Datei in eine (lesbare) ASCII-
        Datei geschrieben werden.
</br>Lies die von mir geschickten Sinusdateien (Sampling-Frequenz: 16 kHz)
</br>Bestimme aus den resultierenden Zahlenfolgen in der ASCII-Datei die Frequenz der Sinus-
        Schwingungen.</p>
<audio controls><source src="audio/sine_hi03.wav" type="audio/wav"></audio>
<audio controls><source src="audio/sine_lo03.wav" type="audio/wav"></audio>
<p>
</br><b>Verarbeite Datei:</b> sine_hi03.wav
</br><b>Sample-Rate:</b> 16000.0 Hz
</br><b>ASCII-Datei erstellt:</b> ./data h/sine_hi_output.txt
</br><b>Output sine_hi03:</b><br><a href="dateien/sine_hi_output.txt" download>Download Text File</a>
</p>

<p>
</br><b>Verarbeite Datei:</b> sine_lo03.wav
</br><b>Sample-Rate:</b> 16000.0 Hz
</br><b>ASCII-Datei erstellt:</b> ./data l/sine_lo_output.txt
</br><b>Output sine_lo03</b><br><a href="dateien/sine_lo_output.txt" download>Download Text File</a>
</p>  
<p><b>Output:</b></p>
<p>
</br><img src="bilder/sine_dateien_output.jpeg" height="100" alt="Bild kann nicht geladen werden.">
</p>

<p>
</br>Frequenz der Sinusschwingung = Samplingfrequenz (Abtastfrequenz) / Anzahl der Werte pro Periode   
</br>Berechnung für die Musik-Datei <b>sine_hi03.wav</b>
</br>Anzahl der Werte pro Periode = 8
</br>Frequenz der Sinusschwingung = 8000 / 8 = 1000 Hz
<p>
</br><b>Begründung:</b>
</br>Die Frequenz einer periodischen Funktion ist invers proportional zur Anzahl der Abtastungen pro Periode.
</br>Da sich die Werte nach 8 Abtastungen wiederholen, entspricht dies einer vollständigen Sinusperiode,
</br>und somit bestimmt die Anzahl der Abtastungen zusammen mit der Samplingfrequenz die Frequenz der Schwingung.
</p>
</br>Berechnung für die Musik-Datei <b>sine_lo03.wav</b>
</br>Anzahl der Werte pro Periode = 16
</br>Frequenz der Sinusschwingung = 8000 / 16 = 500 Hz
</br><b>Begründung:</b>
</br>Die Periode dieser Sinusschwingung erstreckt sich über 16 Werte, das bedeutet, dass die Schwingung langsamer ist als die vorherige,
</br>die 8 Werte pro Periode hatte. Die Frequenz ist die Anzahl der vollständigen Schwingungen pro Sekunde,
</br>und sie hängt davon ab, wie viele Werte eine Periode darstellen und wie häufig diese Werte pro Sekunde abgetastet werden.
</br>Da sich das Muster nach 16 Werten wiederholt und die Samplingfrequenz bekannt ist (angenommene 8000 Hz), ergibt sich eine Schwingungsfrequenz von 500 Hz.
</p>
<br><h3>Aufgabe 2 b.</h3>
<p>Überprüfe deine Schätzung mit dem Programm PRAAT. (Vorgehensweise: Read file..., To
        Spectrum..., Edit)</p>
<p></br><b>sine_hi03.wav</b>:</p>
</br><img src="bilder/spuctrum_sine_hi03.jpeg" height="500" alt="Bild kann nicht geladen werden.">
<p></br><b>sine_lo03.wav</b>:</p>
</br><img src="bilder/spuctrum_sine_lo03.jpeg" height="500" alt="Bild kann nicht geladen werden.">


<br><h3>Aufgabe 2 c.</h3>
<p>Bei der zeitlichen Diskretisierung eines Analogsignals muss das sogenannte Abtasttheorem
        eingehalten werden. </br>Wie lautet es und wie lässt sich der Grenzfall, für den es gerade noch gilt,
        illustrieren? </br>Erstelle hierzu eine Zeichnung und erläutere.</p>
<p><b>fa​≥2⋅fmax​</b>
</br>- Fa à Abtastfrequenz
</br> - Fmax à maximale Frequenzkomponente des zu abtastenden Signals
</br> <b>Definition:</b> Das Abtasttheorem besagt, dass die Abtastfrequenz mindestens doppelt so hoch sein muss wie die 
</br>höchste im Signal vorkommende Frequenz, um das Signal korrekt zu rekonstruieren.
</br>Wird das Signal mit einer geringeren Frequenz als dem Doppelten der maximalen Frequenz abgetastet,
</br> tritt der Effekt des Aliasings auf, bei den Frequenzen falsch dargestellt werden und somit Informationen verloren gehen       
</br><img src="bilder/Ue1Aufg2c.jpg" height="200" alt="Bild kann nicht geladen werden.">
</br>- Zwei Punkte pro Periode
</br>- Abtastpunkte liegen auf den Extremen der Kurve (Maximum, Minimum)</p>

<br><h3>Aufgabe 2 d.</h3>
<p>Bei herkömmlichen Soundkarten tritt systembedingt kein Aliasing auf, weil das Audiosignal stets</br>
        geeignet vorbehandelt wird. Wie sieht diese Vorbehandlung aus?</p>
<p>Um Aliasing zu verhindern, wird das Audiosignal einem Tiefpassfilter unterzogen, bevor es digitalisiert wird. 
</br>Dieser Tiefpassfilter/   Anti-Aliasing-Filter, entfernt Frequenzen, die über der Nyquist-Frequenz liegen (halbe Abtastrate). 
</br>Indem hohen Frequenzen entfernt werden, wird verhindert, dass sie während der Digitalisierung als niedrigere,
</br> unerwünschte Frequenzen erscheinen und somit das Signal verfälschen
</br>- Tiefpassfilter/ Anti- Aliasing- Filter à
</br> o Für Datenerfassungssysteme erforderlich
</br> o Sicherstellung, dass alle abgetasteten Signale genau rekonstruiert werden können
</br> o Filtereigenschaften à Bandbreite, Amplitudenauflösung, Abtastrate
</br> - Nyquist- Frequenz à halbe Abtastfrequenz/rate</p>

<br><h3>Aufgabe 2 e.</h3>
<p>Mit einem kleinen Trick lässt sich Aliasing jedoch nachweisen. Diese auch als Down-Sampling
        bekannte Methode besteht darin, </br>dass man bei einer WAV-Datei z.B. jeden zweiten Abtastwert
        wegwirft.</br> Man erhält so eine Wellenform, die genau die Hälfte der ursprünglichen Abtastfrequenz
        aufweist.</br> Wenn man das Signal nicht vorher bandbegrenzt hat, können Aliasing-Verzerrungen
        hörbar werden.</br> Modifiziere wave_io dahingehend, dass vom eingelesenen Audiosignal jeder zweite Abtastwert
        verworfen wird und das resultierende Signal abgespeichert wird.</br> Der Header muss natürlich
        entsprechend verändert werden</p>
<p></br>Musik-Datei <b>musik_Bytewave.wav</b>:</p>
</br><img src="bilder/downSampled_musik_Bytewave.jpeg" height="250" alt="Bild kann nicht geladen werden.">
<p></br>Sprache-Datei <b>Sprache_Bytewave.wav</b>:</p>
</br><img src="bilder/downSampled_Sprache_Bytewave.jpeg" height="250" alt="Bild kann nicht geladen werden.">


<br><h3>Aufgabe 2 f.</h3>
<p>Wende das erstellte Programm auf die von mir geschickten Sinusdateien an (sine_hiXX.wav und
        sine_loXX.wav) an. </br>Welche Frequenzen erscheinen nach dem Down-Sampling? Was würde
        passieren, wenn man geeignet bandbegrenzen würde?</p>
<p></br><b>sine_hi03.wav</b>:</p>
</br><img src="bilder/downSampled_sine_hi03.jpeg" height="250" alt="Bild kann nicht geladen werden.">
<p></br><b>sine_lo03.wav</b>:</p>
</br><img src="bilder/downSampled_sine_lo03.jpeg" height="250" alt="Bild kann nicht geladen werden.">
<p></br><b>Frequenzen nach dem Downsampling:</b></br>- Wenn das Originalsignal Frequenzen im Bereich von 0 bis 8 kHz hatte, bleiben diese Frequenzen auch nach dem Downsampling korrekt erhalten.
</br>- Frequenzen oberhalb von 8 kHz werden jedoch nach dem Downsampling als tieferliegende Frequenzen interpretiert, weil sie die neue Abtastfrequenz überschreiten.
</br>Dies führt zu Aliasing, also einer Überlagerung von hohen Frequenzen als niedrigere Frequenzen.</p>
<p>Um Aliasing zu verhindern, sollte das Signal vor dem Downsampling bandbegrenzt werden.
         Das bedeutet, man müsste mit einem Tiefpassfilter alle Frequenzen oberhalb der halben Abtastfrequenz (hier 8 kHz) entfernen. 
         Dadurch bleiben nur die Frequenzen, die korrekt dargestellt werden können, und Aliasing wird vermieden.

        Mit einer geeigneten Bandbegrenzung würde das Downsampled-Signal die richtigen Frequenzen ohne Verzerrungen darstellen, da alle problematischen hohen Frequenzen herausgefiltert würden.</p>

<br><h3>Aufgabe 2 g.</h3>
<p>Nun wende das Downsampling auf deine Sprachdatei an und beschreibe, wie sich der Klang
        verändert. </br>Erkläre, warum das passiert!</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 a.</h3>
<p>Die herkömmlichen PC-Soundkarten arbeiten meist entweder mit 16 oder 8 bit-Auflösung. </br>Wie
        groß ist die Anzahl bei diesen beiden Werten darstellbaren Amplitudenwerten?</p>
<p>Allgemein: Anzahl der Werte = 2^bits
</br> 16 bit-Auflösung = 2^16 = 65.536
</br> 8 bit-Auflösung = 2^8 = 256
</p>

<br><h3>Aufgabe 3 b.</h3>
<p>Modifiziere wave_io dahingehend, dass die Bitanzahl reduziert wird.</br> Dazu werden alle Samples
        durch eine Potenz von 2 geteilt (Integer-Division ohne Rest).</br> Damit das resultierende Signal nicht
        leiser wird als das Original, wird die Operation durch Multiplikation mit derselben 2er Potenz
        kompensiert. </br>Zu beachten: Der Datentyp hat nach wie vor 16 bit!</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 c.</h3>
<p>Mit dem entstandenen Programm sollen nun die in Aufgabe 1 erzeugten Wave-Dateien (Sprache
        und Musik) bitreduziert werden. </br>Ab welcher Bitanzahl tritt eine hörbare, also deutliche
        Verschlechterung der Qualität ein? </br>Bei wie viel Bit ist das Sprachsignal noch verständlich?</p>
<p>Bei einer Reduzierung von 8bit hört man schon eine hörbare Verschlechterung bei der Musik-Datei
        <br> Musik_8_Bit
        <br><audio controls><source src="audio/Musik_8_Bit.wav" type="audio/wav"></audio>
        <br><img src="bilder/spectogram_musik_8.jpg" height="200" alt="Bild kann nicht geladen werden."> 
        <br> <br> 
        <br>Ab 4bit ist die Musik fast nicht mehr zu erkennen
        <br>Musik_4_Bit
        <br><audio controls><source src="audio/Musik_4_Bit.wav" type="audio/wav"></audio>
        <br><img src="bilder/spectogram_musik_4.jpg" height="200" alt="Bild kann nicht geladen werden.">
        <br> <br><br> Bei der Sprach-Datei ist die Stimme bei 8bit noch deutlich zu erkennen, zwar hört man ein
        leichtes Rauschen, aber ist noch alles klar zu erkennen
        <br> Sprache_8_Bit
        <br><audio controls><source src="audio/Sprache_8_Bit.wav" type="audio/wav"></audio>
        <br><img src="bilder/spectogram_sprache_8.jpg" height="200" alt="Bild kann nicht geladen werden.">
        <br> <br><br>Bis zu einer Reduzierung auf 4 bit ist es noch möglich die Sprache in einer schlechter Qualität
        noch zu verstehen
        <br> Sprache_6_Bit
         <br><audio controls><source src="audio/Sprache_6_Bit.wav" type="audio/wav"></audio>
        <br><img src="bilder/spectogram_sprache_6.jpg" height="200" alt="Bild kann nicht geladen werden.">
        <br> <br> Sprache_4_Bit
        <br><audio controls><source src="audio/Sprache_4_Bit.wav" type="audio/wav"></audio>
        <br><img src="bilder/spectogram_sprache_4.jpg" height="200" alt="Bild kann nicht geladen werden.">
</p>

<br><h3>Aufgabe 3 d.</h3>
<p>Was charakterisiert das entstehende Quantisierungsgeräusch bei der Bitreduzierung und macht es
        besonders störend?</p>
<p>- Ist weitgehend unabhängig von der Amplitude/Lautstärke des Nutzsignals, aber bei leisen Passagen stärker wahrnehmbar
        <br>- Entsteht durch den Quantisierungsfehler bei der Umwandlung von wertekontinuierlichen zu wertediskreten Signalen
        <br>- Das Rauschen ist zufällig verteilt
        <br>- Tritt im gesamten Frequenzbereich auf, wobei bestimmte Bereiche stärker betroffen sein können, und beeinträchtigt die Klangqualität insgesamt
        <br>- Ist unabhängig vom Nutzsignal und daher auch bei leisen Passagen hörbar
        <br>- Durch zufällige Verteilung ist das Rauschen schwer vorhersehbar und dadurch schwieriger zu unterdrücken</p>

<br><h3>Aufgabe 3 e.</h3>
<p>Modifiziere dein Programm noch einmal so, dass auch das Differenzsignal zwischen Original und
        bitreduziertem Signal, d.h. der Quantisierungsfehler ausgegeben werden kann.</br> Dabei musst du
        bedenken, dass z.B. bei der 1 Bit Reduzierung das Quantisierungsrauschen nur von -1 bis +1
        verlaufen würde. </br>Dieser Wertebereich wäre viel zu klein, als dass man das Rauschen beim
        Abspielen als 16bit-Wert noch hören könnte.</br> Daher muss das Rauschen durch Multiplikation mit
        einer 2er Potenz verstärkt werden.</br> In anderen Worten: Hat man vorher durch 2^n geteilt, sollte
        man das Differenzsignal vor dem Abspeichern mit 2^(16-n-1) multiplizieren. </br>So ist sichergestellt,
        dass der Verstärkungsfaktor mit der Anzahl der gelöschten Bits kleiner wird</p>
<p><!--Loesung--></p>

<br><h3>Aufgabe 3 f.</h3>
<p>Welchen Charakter hat das Rauschen bei einer Reduktion um 1bit und wie verändert es sich bei
        zunehmender Bit-Reduktion?</p>
<p>Wenn die Bit Anzahl um 1 reduziert wird, entsteht ein geringfügiges Rauschen im Differenzsignal. 
        <br> Je mehr Bits weggenommen werden, desto stärker wird auch das Rauschen und das ursprüngliche Signal
        <br> klingt zunehmend verzerrt und weniger klar.</p>

</body>
</html>
